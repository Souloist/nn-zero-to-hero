{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357703cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# Worksheet 2b - Single-Layer Perceptron\n",
    "\n",
    "This is the third in a series of companion worksheets for for Andrej Karpathy's [Neural Networks: Zero To Hero](https://karpathy.ai/zero-to-hero.html) videos.\n",
    "\n",
    "It corresponds to roughly the second half of the second video in the series, named \"[The spelled-out intro to language modeling: building makemore](https://www.youtube.com/watch?v=PaCmpygFfXo)\".\n",
    "\n",
    "The rest of the worksheets are listed in the README [here](https://github.com/Russ741/karpathy-nn-z2h/).\n",
    "\n",
    "The overall objective of this worksheet is to write code that generates a word that is similar to a set of example words it is trained on.\n",
    "It does so using a single-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994ac08",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Prerequisite: Load worksheet utilities and download word list\n",
    "\n",
    "The following cell imports [utility functions](https://github.com/Russ741/karpathy-nn-z2h/blob/main/worksheets/worksheet_utils.py) that this worksheet depends on.\n",
    "If the file isn't already locally available (e.g. for Colab), it downloads it from GitHub.\n",
    "\n",
    "Similarly, if this directory does not already contain names.txt, it downloads it from\n",
    "[the makemore GitHub repository](https://github.com/karpathy/makemore/blob/master/names.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226b3f97",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worksheet_utils found.\n",
      "word file found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from worksheet_utils import *\n",
    "    print(\"worksheet_utils found.\")\n",
    "except ModuleNotFoundError:\n",
    "    utils_local_filename = \"worksheet_utils.py\"\n",
    "    print(f\"Downloading worksheet_utils.\")\n",
    "    with urllib.request.urlopen(\"https://raw.githubusercontent.com/Russ741/karpathy-nn-z2h/main/worksheets/worksheet_utils.py\") as response:\n",
    "        with open(utils_local_filename, mode=\"xb\") as utils_file:\n",
    "            shutil.copyfileobj(response, utils_file)\n",
    "    from worksheet_utils import *\n",
    "\n",
    "WORDS_PATH = \"names.txt\"\n",
    "if os.path.isfile(WORDS_PATH):\n",
    "    print(\"word file found.\")\n",
    "else:\n",
    "    print(\"word file not found, downloading.\")\n",
    "    with urllib.request.urlopen(\"https://github.com/karpathy/makemore/raw/master/names.txt\") as response:\n",
    "        with open(WORDS_PATH, mode=\"xb\") as words_file:\n",
    "            shutil.copyfileobj(response, words_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd67f70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Preamble: Load data\n",
    "\n",
    "Objective: Write a function that:\n",
    " * Returns a list of strings\n",
    "   * Each string should be equal to the word from the corresponding line of the word file (at ```WORDS_PATH```)\n",
    "   * The strings should not include line-break characters\n",
    "\n",
    "Note: In practice, the order of the strings in the returned list does not matter, but for the\n",
    "test to pass, they should be in the same order in the list as in the word file.\n",
    "\n",
    "Video: [0:03:03](https://youtu.be/PaCmpygFfXo?t=183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d27d00",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_words():\n",
    "    words = []\n",
    "    with open(WORDS_PATH, \"r\") as f:\n",
    "        for word in f:\n",
    "            words.append(word.strip())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a115e8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_words looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_words():\n",
    "    expect_type(\"loaded_words\", loaded_words, list)\n",
    "    expect_eq(\"len(loaded_words)\", len(loaded_words), 32033)\n",
    "    expect_eq(\"loaded_words[0]\", loaded_words[0], \"emma\")\n",
    "    expect_eq(\"loaded_words[-1]\", loaded_words[-1], \"zzyzx\")\n",
    "    print(\"load_words looks good. Onwards!\")\n",
    "loaded_words = load_words()\n",
    "test_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b336336",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 1: Generate bigrams\n",
    "\n",
    "Objective: Populate the variable ```bigrams``` with a list of bigrams (2-element tuples) of adjacent characters in ```words```.\n",
    "\n",
    "Treat the start and end of each word as the character '.'\n",
    "\n",
    "Video: [0:06:24](https://youtu.be/PaCmpygFfXo?t=384) and [0:21:55](https://youtu.be/PaCmpygFfXo?t=1315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74456712",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_bigrams(words):\n",
    "    bigrams = []\n",
    "    for word in words:\n",
    "        f_word = f\".{word}.\"\n",
    "        for ch1, ch2 in zip(f_word, f_word[1:]):\n",
    "            bigrams.append((ch1, ch2))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded04123",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_bigrams looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_generate_bigrams():\n",
    "    bigrams = generate_bigrams(loaded_words)\n",
    "    expect_type(\"bigrams\", bigrams, list)\n",
    "    expect_eq(\"count of ('.', 'm') bigrams\", bigrams.count(('.', 'm')), 2538)\n",
    "    expect_eq(\"count of ('a', 'b') bigrams\", bigrams.count(('a', 'b')), 541)\n",
    "    expect_eq(\"count of ('s', '.') bigrams\", bigrams.count(('s', '.')), 1169)\n",
    "    print(\"generate_bigrams looks good. Onwards!\")\n",
    "test_generate_bigrams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa6640",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2: Map characters to indices\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a list of char, char tuples representing all of the bigrams in a word list\n",
    "\n",
    "And returns:\n",
    "* a dict (```stoi```) where\n",
    "  * the key is a character from ```words``` (including '.' for start/end),\n",
    "  * the value is a unique integer, and\n",
    "  * all the values are in the range from 0 to ```len(stoi) - 1``` (no gaps)\n",
    "\n",
    "We'll use these unique integers as an index to represent the characters in a Tensor in later steps\n",
    "\n",
    "Note that for this list of words, the same value of ```stoi``` could be generated without looking at the words at all,\n",
    "but simply by using all the lowercase letters and a period. This approach would be more efficient for this exercise,\n",
    "but will not generalize well conceptually to more complex models in future exercises.\n",
    "\n",
    "Video: [0:15:40](https://youtu.be/PaCmpygFfXo?t=940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f0b000",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def get_stoi(bigrams):\n",
    "    sorted_bigrams = sorted(set(\"\".join(chain(*bigrams))))\n",
    "    return {k:v for v, k in enumerate(sorted_bigrams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "457140ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_stoi looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def test_get_stoi():\n",
    "    bigrams = [\n",
    "        ('.', 'h'),\n",
    "        ('h', 'i'),\n",
    "        ('i', '.'),\n",
    "        ('.', 'b'),\n",
    "        ('b', 'y'),\n",
    "        ('y', 'e'),\n",
    "        ('e', '.'),\n",
    "    ]\n",
    "    expected_s = sorted(['.', 'h', 'i', 'b', 'y', 'e'])\n",
    "    stoi = get_stoi(bigrams)\n",
    "    expect_type(\"stoi\", stoi, dict)\n",
    "    s = sorted(stoi.keys())\n",
    "    expect_eq(\"stoi keys when sorted\", s, expected_s)\n",
    "    expected_i = list(range(len(s)))\n",
    "    i = sorted(stoi.values())\n",
    "    expect_eq(\"stoi values when sorted\", i, expected_i)\n",
    "    print(\"get_stoi looks good. Onwards!\")\n",
    "test_get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124bf0ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 3: Map indices to characters\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a dict (```stoi```) as defined in step 2\n",
    "\n",
    "And returns:\n",
    "* a dict (```itos```) where ```itos``` contains the same key-value pairs as ```stoi``` but with keys and values swapped.\n",
    "\n",
    "E.g. if ```stoi == {'.' : 0, 'b' : 1, 'z', 2}```, then ```itos == {0 : '.', 1 : 'b', 2 : 'z'}```\n",
    "\n",
    "Video: [0:18:49](https://youtu.be/PaCmpygFfXo?t=1129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02ff4980",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_itos(stoi):\n",
    "    return {v:k for k, v in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07dff8c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_itos looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def test_get_itos():\n",
    "    stoi = {elem:idx for idx, elem in enumerate(string.ascii_lowercase + \".\")}\n",
    "    itos = get_itos(stoi)\n",
    "    expect_type(\"itos\", itos, dict)\n",
    "    for c in string.ascii_lowercase + \".\":\n",
    "        c_i = stoi[c]\n",
    "        expect_eq(f\"itos.get({c_i})\", itos.get(c_i), c)\n",
    "    print(\"get_itos looks good. Onwards!\")\n",
    "test_get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d225cfd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 4: Split bigrams into inputs and outputs\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a list ```bigrams``` as defined in step 1, and\n",
    "* a dict ```stoi``` as defined in step 2\n",
    "\n",
    "And returns:\n",
    "* a one-dimensional torch.Tensor ```x``` with all of the first characters in the tuples in ```bigrams```\n",
    "* a one-dimensional torch.Tensor ```y``` with all of the second characters in the tuples in ```bigrams```\n",
    "* Note: Both output tensors should be the same length as ```bigrams```\n",
    "\n",
    "Video: [1:05:25](https://youtu.be/PaCmpygFfXo?t=3925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa65044d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_x_and_y(bigrams, stoi):\n",
    "    xs, ys = [], []\n",
    "    for bigram in bigrams:\n",
    "        ch1, ch2 = bigram\n",
    "        ix1 = stoi.get(ch1)\n",
    "        ix2 = stoi.get(ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "    return torch.tensor(xs), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90eedd4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_x_and_y looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_get_x_and_y():\n",
    "    bigrams = [\n",
    "        ('.', 'h'),\n",
    "        ('h', 'i'),\n",
    "        ('i', '.'),\n",
    "        ('.', 'b'),\n",
    "        ('b', 'y'),\n",
    "        ('y', 'e'),\n",
    "        ('e', '.'),\n",
    "    ]\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'h': 1,\n",
    "        'i': 2,\n",
    "        'b': 3,\n",
    "        'y': 4,\n",
    "        'e': 5,\n",
    "    }\n",
    "    x, y = get_x_and_y(bigrams, stoi)\n",
    "    expect_eq(\"x[0]\", x[0], 0)\n",
    "    expect_eq(\"y[0]\", y[0], 1)\n",
    "    expect_eq(\"x[-2]\", x[-2], 4)\n",
    "    expect_eq(\"y[-2]\", y[-2], 5)\n",
    "    print(\"get_x_and_y looks good. Onwards!\")\n",
    "test_get_x_and_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa68ac9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 5: Provide initial values for the model parameters\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a dict ```stoi``` as defined in step 2\n",
    "  * the length of ```stoi``` will be referred to as ```stoi_n```\n",
    "* a ```torch.Generator``` (```gen```) to provide (pseudo)random initial values for the parameters\n",
    "\n",
    "And returns:\n",
    "* a pytorch.Tensor ```W``` of shape (```stoi_n```, ```stoi_n```) where each element is randomly generated\n",
    "* a pytorch.Tensor ```b``` of shape (1, ```stoi_n```)\n",
    "  * The elements of ```b``` can be zero\n",
    "\n",
    "Video: [1:14:03](https://youtu.be/PaCmpygFfXo?t=4433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6da9ecd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def initialize_w_b(stoi, gen):\n",
    "    stoi_n = len(stoi)\n",
    "    W = torch.rand((stoi_n, stoi_n), generator=gen, dtype=torch.float64, requires_grad=True)\n",
    "    b = torch.zeros(1, stoi_n, dtype=torch.float64, requires_grad=True)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af5317f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_w_b looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_initialize_w_b():\n",
    "    stoi = {'q': 0, 'w': 1, 'e': 2, 'r': 3}\n",
    "    expected_s_ct = 4\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(12345)\n",
    "    W, b = initialize_w_b(stoi, gen)\n",
    "    expect_eq(\"len(W)\", len(W), expected_s_ct)\n",
    "    for row_idx in range(len(W)):\n",
    "        expect_eq(f\"len(W[{row_idx}])\", len(W[row_idx]), expected_s_ct)\n",
    "        for col_idx in range(len(W[row_idx])):\n",
    "            if (val := W[row_idx][col_idx]) == 0.0:\n",
    "                raise Exception(f\"Expected W[{row_idx}][{col_idx}] to be non-zero.\")\n",
    "    expect_eq(\"W.requires_grad\", W.requires_grad, True)\n",
    "    expect_eq(\"b.requires_grad\", b.requires_grad, True)\n",
    "    expect_eq(\"b.shape\", b.shape, (1, expected_s_ct))\n",
    "    print(\"initialize_w_b looks good. Onwards!\")\n",
    "test_initialize_w_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d079f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 6: Forward propagation\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a pytorch.Tensor ```x``` of training or testing inputs\n",
    "* pytorch.Tensors ```W``` and ```b``` representing the parameters of the model\n",
    "\n",
    "And returns:\n",
    "* a pytorch.Tensor ```y_hat``` of the model's predicted outputs for each input in x\n",
    "  * The predicted outputs for a given sample should sum to 1.0\n",
    "  * The shape of ```y_hat``` should be (```len(x)```, ```len(W)```)\n",
    "    * Note that ```len(W)``` represents the number of different characters in the word list\n",
    "\n",
    "Video: [1:15:12](https://youtu.be/PaCmpygFfXo?t=4512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "686d9594",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def forward_prop(x, W, b):\n",
    "    xenc = F.one_hot(x, len(W)).double()\n",
    "    logits = xenc @ W + b\n",
    "    \n",
    "    counts = logits.exp() # get \"fake\" counts\n",
    "    probs = counts / counts.sum(1, keepdims=True) # Doing exponentiation followed by noramlization is known as softmax \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19d372f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_prop looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_forward_prop():\n",
    "    x = torch.tensor([\n",
    "        1,\n",
    "        0,\n",
    "    ])\n",
    "\n",
    "    W = torch.tensor([\n",
    "        [0.1, 0.9, 0.2, 0.01],\n",
    "        [0.04, 0.2, 1.6, 0.25],\n",
    "        [0.02, 0.03, 0.7, 0.01],\n",
    "    ], dtype=torch.float64)\n",
    "\n",
    "    b = torch.tensor([\n",
    "        0.01, 0.02, 0.03, 0.04\n",
    "    ], dtype=torch.float64)\n",
    "\n",
    "    expected_y_hat = torch.tensor([\n",
    "        [0.1203, 0.1426, 0.5841, 0.1530],\n",
    "        [0.1881, 0.4228, 0.2120, 0.1771],\n",
    "    ], dtype=torch.float64)\n",
    "\n",
    "    y_hat = forward_prop(x, W, b)\n",
    "\n",
    "    expect_tensor_close(\"y_hat for test case\", y_hat, expected_y_hat)\n",
    "    print(\"forward_prop looks good. Onwards!\")\n",
    "test_forward_prop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186fb1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 0
   },
   "source": [
    "### Step 7: Loss calculation\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a pytorch.Tensor ```y_hat``` of predicted outputs for a particular set of inputs\n",
    "* a pytorch.Tensor ```y``` of actual outputs for the same set of inputs\n",
    "\n",
    "And returns:\n",
    "* a floating-point value representing the model's negative log likelihood loss for that set of inputs\n",
    "\n",
    "Video: [1:35:49](https://youtu.be/PaCmpygFfXo&t=5749)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "febe33b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_loss(y_hat, y):\n",
    "    loss = -y_hat[torch.arange(len(y)), y].log().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5cf56b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_loss looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "def test_calculate_loss():\n",
    "    y = torch.tensor([2], dtype=torch.int64)\n",
    "    y_hat = torch.tensor([\n",
    "        [0.0, 0.0, 1.0, 0.0]\n",
    "    ])\n",
    "    expect_close(\"loss for first example\", calculate_loss(y_hat, y), 0.0)\n",
    "\n",
    "    y = torch.tensor([2, 0], dtype=torch.int64)\n",
    "    y_hat = torch.tensor([\n",
    "        [0.09, 0.09, exp(-0.5), 0.09],\n",
    "        [exp(-0.1), 0.01, 0.02, 0.03]\n",
    "    ])\n",
    "    expect_close(\"loss for second example\", calculate_loss(y_hat, y), 0.3)\n",
    "    print(\"calculate_loss looks good. Onwards!\")\n",
    "test_calculate_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621444d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 8: Gradient descent\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* pytorch.Tensors ```W``` and ```b``` representing the parameters of the model\n",
    "* a floating-point value ```learning_rate``` representing the overall size of adjustment to make to the parameters\n",
    "\n",
    "And returns:\n",
    "* the updated pytorch.Tensors ```W``` and ```b```\n",
    "  * Note: Updating the parameters in-place is desirable, but for ease of testing, please return them regardless.\n",
    "\n",
    "Video: [1:41:26](https://youtu.be/PaCmpygFfXo?t=6086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88f71727",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def descend_gradient(W, b, learning_rate):\n",
    "    W.data += -learning_rate * W.grad\n",
    "    b.data += -learning_rate * b.grad\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c63eed7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descend_gradient looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_descend_gradient():\n",
    "    W = torch.tensor([\n",
    "        [1.0, 2.0,],\n",
    "        [3.0, -4.0],\n",
    "        [-5.0, 6.0],\n",
    "    ])\n",
    "    W.grad = torch.tensor([\n",
    "        [-2.0, 1.0],\n",
    "        [0.0, -2.0],\n",
    "        [4.0, 1.0]\n",
    "    ])\n",
    "    b = torch.tensor([\n",
    "        1.0,\n",
    "        2.0,\n",
    "    ])\n",
    "    b.grad = torch.tensor([\n",
    "        -1.0,\n",
    "        0.5,\n",
    "    ])\n",
    "\n",
    "    new_w, new_b = descend_gradient(W, b, 3.0)\n",
    "\n",
    "    expected_new_w = torch.tensor([\n",
    "        [7.0, -1.0],\n",
    "        [3.0, 2.0],\n",
    "        [-17.0, 3.0]\n",
    "    ])\n",
    "    expect_tensor_close(\"new W for test case\", new_w, expected_new_w)\n",
    "\n",
    "    expected_new_b = torch.tensor([\n",
    "        4.0,\n",
    "        0.5,\n",
    "    ])\n",
    "    expect_tensor_close(\"new b for test case\", new_b, expected_new_b)\n",
    "    print(\"descend_gradient looks good. Onward!\")\n",
    "test_descend_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5509668",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 9: Train model\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* pytorch.Tensors ```x``` and ```y``` as described in Step 4\n",
    "* pytorch.Tensors ```W``` and ```b``` as described in Step 5\n",
    "* a floating-point value ```learning_rate``` representing the overall size of adjustment to make to the parameters\n",
    "\n",
    "Updates the values of W and b to fit the data slightly better\n",
    "\n",
    "And returns:\n",
    "* the loss as defined in Step 6\n",
    "\n",
    "Implementation note: this function should make use of several of the functions you've previously implemented.\n",
    "\n",
    "Video: [1:42:55](https://youtu.be/PaCmpygFfXo?t=6175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d698d29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model(x, y, W, b, learning_rate):\n",
    "    ## Forward pass\n",
    "    probs = forward_prop(x, W, b)\n",
    "    loss = calculate_loss(probs, y)\n",
    "    print(loss)\n",
    "\n",
    "    ## Backward pass\n",
    "    W.grad = None\n",
    "    b.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    descend_gradient(W, b, learning_rate)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d51e246",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1019, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "train_model looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_train_model():\n",
    "    x = torch.tensor([\n",
    "        0,\n",
    "        1,\n",
    "        2,\n",
    "    ])\n",
    "    y = torch.tensor([\n",
    "        1,\n",
    "        2,\n",
    "        0,\n",
    "    ])\n",
    "    W = torch.tensor([\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0],\n",
    "    ], dtype=torch.float64, requires_grad=True)\n",
    "    b = torch.tensor([\n",
    "        0.1,\n",
    "        0.2,\n",
    "        0.3,\n",
    "    ], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    loss = train_model(x, y, W, b, 2.0)\n",
    "\n",
    "    expected_W = torch.tensor([\n",
    "        [0.7996, 1.4452, 0.7552],\n",
    "        [0.7996, 0.7785, 1.4219],\n",
    "        [1.4663, 0.7785, 0.7552]\n",
    "    ], dtype=torch.float64)\n",
    "    expect_tensor_close(\"W for test case\", W, expected_W)\n",
    "\n",
    "    expected_b = torch.tensor([\n",
    "        0.1654,\n",
    "        0.2022,\n",
    "        0.2323\n",
    "    ], dtype=torch.float64)\n",
    "    expect_tensor_close(\"b for test case\", b, expected_b)\n",
    "    print(\"train_model looks good. Onward!\")\n",
    "test_train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf582849",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 10: Generate words\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* pytorch.Tensors ```W``` and ```b``` as described in Step 5\n",
    "* a dict ```stoi``` as described in Step 2\n",
    "* a dict ```itos``` as described in Step 3\n",
    "* a torch.Generator to use for pseudorandom selection of elements\n",
    "\n",
    "Repeatedly generates a probability distribution for the next letter to select given the last letter\n",
    "\n",
    "And returns\n",
    "* a string representing a word generated by repeatedly sampling the probability distribution\n",
    "\n",
    "Video: [1:54:31](https://youtu.be/PaCmpygFfXo?t=6871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76d75463",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_word(W, b, stoi, itos, gen):\n",
    "    char = '.'\n",
    "    word = \"\"\n",
    "    while True:\n",
    "        x = torch.tensor([stoi[char]])\n",
    "        probability_distribution = forward_prop(x, W, b)\n",
    "        sample = torch.multinomial(probability_distribution, 1, generator=gen).item()\n",
    "        char = itos[sample]\n",
    "        if char == '.':\n",
    "            break\n",
    "        word += char\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3425c382",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_word looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_generate_word():\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'o': 1,\n",
    "        'n': 2,\n",
    "        'w': 3,\n",
    "        'a': 4,\n",
    "        'r': 5,\n",
    "        'd': 6,\n",
    "    }\n",
    "    stoi_n = len(stoi)\n",
    "    itos = {v:k for k,v in stoi.items()}\n",
    "\n",
    "    W = torch.zeros((stoi_n, stoi_n), dtype=torch.float64)\n",
    "    b = torch.zeros((1, stoi_n), dtype=torch.float64)\n",
    "    # These weights result in a probability distribution where the desired next letter is roughly\n",
    "    # 1000x as likely as the others.\n",
    "    for i in range(stoi_n - 1):\n",
    "        W[i][i+1] = 10.0\n",
    "    W[stoi_n - 1][0] = 10.0\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(2147476727)\n",
    "    expect_eq(\"generate_word result for test case\", generate_word(W, b, stoi, itos, gen), \"onward\")\n",
    "    print(f\"generate_word looks good. Onward!\")\n",
    "test_generate_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3cbeb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Finale: Put it all together\n",
    "\n",
    "Objective: Write (and call) a function that:\n",
    "* generates the bigrams and character maps\n",
    "* repeatedly trains the model until its loss is acceptably small\n",
    "  * For reference, the \"perfect\" loss of the probability table approach is approximately 2.4241\n",
    "* uses the model to generate some made-up names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dcfecc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3445, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(3.1357, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(3.0094, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.9365, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.8905, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.8575, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.8317, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.8106, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7925, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7768, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7628, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7502, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7388, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7284, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7188, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7099, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.7016, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6939, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6867, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6799, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6735, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6676, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6619, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6566, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6515, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6467, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6422, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6379, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6337, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6298, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6260, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6225, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6190, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6157, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6126, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6096, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6067, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6039, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.6012, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5986, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5961, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5937, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5914, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5891, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5870, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5849, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5828, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5809, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5790, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5771, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5754, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5736, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5719, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5703, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5687, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5672, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5657, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5642, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5628, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5614, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5601, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5587, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5575, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5562, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5550, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5538, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5526, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5515, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5504, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5493, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5483, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5472, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5462, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5452, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5443, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5433, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5424, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5415, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5406, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5397, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5389, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5380, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5372, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5364, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5356, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5348, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5341, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5333, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5326, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5319, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5312, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5305, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5298, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5292, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5285, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5279, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5272, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5266, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5260, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5254, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5248, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5242, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5237, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5231, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5226, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5220, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5215, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5210, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5204, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5199, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5194, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5189, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5185, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5180, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5175, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5170, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5166, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5161, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5157, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5153, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5148, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5144, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5140, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5136, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5132, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5128, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5124, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5120, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5116, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5112, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5108, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5105, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5101, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5098, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5094, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5091, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5087, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5084, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5080, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5077, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5074, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5070, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5067, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5064, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5061, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5058, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5055, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5052, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5049, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5046, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5043, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5040, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5037, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5035, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5032, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5029, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5026, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5024, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5021, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5019, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5016, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5013, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5011, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5008, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5006, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5004, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.5001, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4999, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4996, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4994, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4992, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4989, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4987, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4985, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4983, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4981, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4978, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4976, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4974, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4972, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4970, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4968, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4966, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4964, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4962, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4960, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4958, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4956, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4954, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4952, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4950, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4948, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4947, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4945, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4943, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4941, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4939, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4938, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4936, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(2.4934, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "loss is 2.4934157612545014\n",
      "n\n",
      "dinaunn\n",
      "daashh\n",
      "tet\n",
      "cnn\n"
     ]
    }
   ],
   "source": [
    "def train_model_and_generate_words():\n",
    "    gen = torch.Generator().manual_seed(12345)\n",
    "    words = load_words()\n",
    "    bigrams = generate_bigrams(words)\n",
    "    stoi = get_stoi(bigrams)\n",
    "    itos = get_itos(stoi)\n",
    "    \n",
    "    x, y = get_x_and_y(bigrams, stoi)\n",
    "    W, b = initialize_w_b(stoi, gen)\n",
    "    for i in range(200):\n",
    "        loss = train_model(x, y, W, b, 5.0)\n",
    "    print(f\"loss is {loss}\")\n",
    "    for i in range(5):\n",
    "        print(generate_word(W, b, stoi, itos, gen))\n",
    "train_model_and_generate_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085814f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
