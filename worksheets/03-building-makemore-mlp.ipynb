{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf99c375",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# Worksheet 3 - Multi-Layer Perceptron\n",
    "\n",
    "This is the fourth in a series of companion worksheets for for Andrej Karpathy's [Neural Networks: Zero To Hero](https://karpathy.ai/zero-to-hero.html) videos.\n",
    "\n",
    "It corresponds to the third video in the series, named \"[Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I)\".\n",
    "\n",
    "The rest of the worksheets are listed in the README [here](https://github.com/Russ741/karpathy-nn-z2h/).\n",
    "\n",
    "The overall objective of this worksheet is to write code that generates a word that is similar to a set of example words it is trained on.\n",
    "It does so using a multi-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e36b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Prerequisite: Load worksheet utilities and download word list\n",
    "\n",
    "The following cell imports [utility functions](https://github.com/Russ741/karpathy-nn-z2h/blob/main/worksheets/worksheet_utils.py) that this worksheet depends on.\n",
    "If the file isn't already locally available (e.g. for Colab), it downloads it from GitHub.\n",
    "\n",
    "Similarly, if this directory does not already contain names.txt, it downloads it from\n",
    "[the makemore GitHub repository](https://github.com/karpathy/makemore/blob/master/names.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41aaddb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worksheet_utils found.\n",
      "word file found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from worksheet_utils import *\n",
    "    print(\"worksheet_utils found.\")\n",
    "except ModuleNotFoundError:\n",
    "    utils_local_filename = \"worksheet_utils.py\"\n",
    "    print(f\"Downloading worksheet_utils.\")\n",
    "    with urllib.request.urlopen(\"https://raw.githubusercontent.com/Russ741/karpathy-nn-z2h/main/worksheets/worksheet_utils.py\") as response:\n",
    "        with open(utils_local_filename, mode=\"xb\") as utils_file:\n",
    "            shutil.copyfileobj(response, utils_file)\n",
    "    from worksheet_utils import *\n",
    "\n",
    "WORDS_PATH = \"names.txt\"\n",
    "if os.path.isfile(WORDS_PATH):\n",
    "    print(\"word file found.\")\n",
    "else:\n",
    "    print(\"word file not found, downloading.\")\n",
    "    with urllib.request.urlopen(\"https://github.com/karpathy/makemore/raw/master/names.txt\") as response:\n",
    "        with open(WORDS_PATH, mode=\"xb\") as words_file:\n",
    "            shutil.copyfileobj(response, words_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf9a07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Preamble: Load data\n",
    "\n",
    "Objective: Write a function that:\n",
    " * Returns a list of strings\n",
    "   * Each string should be equal to the word from the corresponding line of the word file (at ```WORDS_PATH```)\n",
    "   * The strings should not include line-break characters\n",
    "\n",
    "Note: In practice, the order of the strings in the returned list does not matter, but for the\n",
    "test to pass, they should be in the same order in the list as in the word file.\n",
    "\n",
    "Video: [0:09:10](https://youtu.be/TCH_1BHY58I?t=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfb27ce",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_words():\n",
    "    words = []\n",
    "    with open(WORDS_PATH, \"r\") as f:\n",
    "        for word in f:\n",
    "            words.append(word.strip())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e455302b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_words looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_words():\n",
    "    expect_type(\"loaded_words\", loaded_words, list)\n",
    "    expect_eq(\"len(loaded_words)\", len(loaded_words), 32033)\n",
    "    expect_eq(\"loaded_words[0]\", loaded_words[0], \"emma\")\n",
    "    expect_eq(\"loaded_words[-1]\", loaded_words[-1], \"zzyzx\")\n",
    "    print(\"load_words looks good. Onwards!\")\n",
    "loaded_words = load_words()\n",
    "test_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4466",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 1: Map characters to indices\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* ```words``` (list of strings)\n",
    "\n",
    "And returns:\n",
    "* a dict (```stoi```) where\n",
    "  * the key is a character from ```words``` (including '.' for start/end),\n",
    "  * the value is a unique integer, and\n",
    "  * all the values are in the range from 0 to ```len(stoi) - 1``` (no gaps)\n",
    "\n",
    "We'll use these unique integers as an index to represent the characters in a Tensor in later steps\n",
    "\n",
    "Note that for this list of words, the same value of ```stoi``` could be generated without looking at the words at all,\n",
    "but simply by using all the lowercase letters and a period. This approach would be more efficient for this exercise,\n",
    "but will not generalize well conceptually to more complex models in future exercises.\n",
    "\n",
    "Video: [0:09:22](https://youtu.be/TCH_1BHY58I?t=562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90ef782d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def get_stoi(bigrams):\n",
    "    chars = sorted(set((chain(*bigrams))))\n",
    "    stoi = {k:i for i, k in enumerate(chars)}\n",
    "    stoi[\".\"] = 0\n",
    "    return stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58e24291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_stoi looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def test_get_stoi():\n",
    "    bigrams = [\n",
    "        ('.', 'h'),\n",
    "        ('h', 'i'),\n",
    "        ('i', '.'),\n",
    "        ('.', 'b'),\n",
    "        ('b', 'y'),\n",
    "        ('y', 'e'),\n",
    "        ('e', '.'),\n",
    "    ]\n",
    "\n",
    "    stoi = get_stoi(bigrams)\n",
    "\n",
    "    expect_type(\"stoi\", stoi, dict)\n",
    "    s = sorted(stoi.keys())\n",
    "    expected_s = sorted(['.', 'h', 'i', 'b', 'y', 'e'])\n",
    "    expect_eq(\"stoi keys when sorted\", s, expected_s)\n",
    "    i = sorted(stoi.values())\n",
    "    expected_i = list(range(len(s)))\n",
    "    expect_eq(\"stoi values when sorted\", i, expected_i)\n",
    "    print(\"get_stoi looks good. Onwards!\")\n",
    "test_get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6603e1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2: Map indices to characters\n",
    "\n",
    "Objective: Write a function that takes the following arguments:\n",
    "* a dict (```stoi```) as defined in step 2\n",
    "\n",
    "And returns:\n",
    "* a dict (```itos```) where ```itos``` contains the same key-value pairs as ```stoi``` but with keys and values swapped.\n",
    "\n",
    "E.g. if ```stoi == {'.' : 0, 'b' : 1, 'z', 2}```, then ```itos == {0 : '.', 1 : 'b', 2 : 'z'}```\n",
    "\n",
    "Video: [0:09:22](https://youtu.be/TCH_1BHY58I?t=562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f179c5e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_itos(stoi):\n",
    "    return {v:k for k,v in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c0410c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_itos looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def test_get_itos():\n",
    "    stoi = {elem:idx for idx, elem in enumerate(string.ascii_lowercase + \".\")}\n",
    "    itos = get_itos(stoi)\n",
    "    expect_type(\"itos\", itos, dict)\n",
    "    for c in string.ascii_lowercase + \".\":\n",
    "        c_i = stoi[c]\n",
    "        expect_eq(f\"itos[{c_i}]\", itos[c_i], c)\n",
    "    print(\"get_itos looks good. Onwards!\")\n",
    "test_get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c984609",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 3: Generate inputs ```X``` and outputs ```Y```\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* a list of strings (```words``` from the preamble)\n",
    "* a dict of characters to integers (```stoi``` from step 2)\n",
    "* an integer (```block_size```) that specifies how many characters to take into account when predicting the next one\n",
    "\n",
    "And returns:\n",
    "* a two-dimensional torch.Tensor ```X``` with each sequence of characters of length block_size from the words in ```words```\n",
    "* a one-dimensional torch.Tensor ```Y``` with the character that follows each sequence in ```x```\n",
    "\n",
    "Video: [0:09:35](https://youtu.be/TCH_1BHY58I?t=575)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdda3a69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_X_and_Y(words, stoi, block_size):\n",
    "    X, Y = [], []\n",
    "    ## special char \".\" mapped to 0\n",
    "    for w in words:\n",
    "        f_word = f\"{w}.\"\n",
    "        context = [0] * block_size\n",
    "        for char in f_word:\n",
    "            X.append(context)\n",
    "            ix = stoi[char]\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # update context to contain next char as rolling window\n",
    "    return torch.tensor(X), torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91f3ba1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_x_and_y looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_get_X_and_Y():\n",
    "    words = [\n",
    "        \"hi\",\n",
    "        \"bye\",\n",
    "    ]\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'h': 1,\n",
    "        'i': 2,\n",
    "        'b': 3,\n",
    "        'y': 4,\n",
    "        'e': 5,\n",
    "    }\n",
    "    block_size = 3\n",
    "\n",
    "    (X, Y) = get_X_and_Y(words, stoi, block_size)\n",
    "\n",
    "    expected_X = torch.tensor([\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 2],\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 3],\n",
    "        [0, 3, 4],\n",
    "        [3, 4, 5],\n",
    "    ])\n",
    "    expected_Y = torch.tensor([\n",
    "        1,\n",
    "        2,\n",
    "        0,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        0,\n",
    "    ])\n",
    "    expect_tensor_close(\"X for test case\", X, expected_X)\n",
    "    expect_tensor_close(\"Y for test case\", Y, expected_Y)\n",
    "    print(\"get_x_and_y looks good. Onwards!\")\n",
    "test_get_X_and_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b0c03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 4: Initialize vector embedding lookup table ```C```\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* An integer (```indices```) representing the number of indices in ```stoi``` to provide embeddings for\n",
    "* An integer (```embedding_size```) representing the length of each embedding vector\n",
    "* A ```torch.Generator``` (```gen```) to provide (pseudo)random initial values for the parameters\n",
    "\n",
    "And returns:\n",
    "* a ```torch.Tensor``` of ```float64``` (```C```) representing the initial (random) embedding vectors for each index.\n",
    "\n",
    "Video: [0:03:01](https://youtu.be/TCH_1BHY58I?t=181), [0:12:19](https://youtu.be/TCH_1BHY58I?t=739), and [0:38:49](https://youtu.be/TCH_1BHY58I?t=2329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89239d3f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_C(indices, embedding_size, gen):\n",
    "    C = torch.randn(indices, embedding_size, generator=gen, dtype=torch.float64, requires_grad=True)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46893743",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_C looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_get_C():\n",
    "    indices = 7\n",
    "    embedding_size = 4\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(12345)\n",
    "    C = get_C(indices, embedding_size, gen)\n",
    "    expect_type(\"C\", C, torch.Tensor)\n",
    "    expect_eq(\"C.dtype\", C.dtype, torch.float64)\n",
    "    expect_eq(\"C.shape\", C.shape, (indices, embedding_size))\n",
    "    for i in range(len(C)):\n",
    "        for j in range(len(C)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if C[i].equal(C[j]):\n",
    "                raise Exception(f\"Rows {i} and {j} of C are too similar.\\n{C[i]=}\\n{C[j]=}\")\n",
    "    print(\"get_C looks good. Onwards!\")\n",
    "test_get_C()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90e4c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 5: Generate vector embeddings of X\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* a two-dimensional torch.Tensor ```X``` as defined in step 3\n",
    "* a two-dimensional torch.Tensor ```C``` as defined in step 4\n",
    "\n",
    "And returns:\n",
    "* a **two**-dimensional torch.Tensor ```emb``` where each row is the concatenated vector embeddings of the indices of the corresponding row in X\n",
    "  * Note the slight difference from the video, where emb is *three*-dimensional\n",
    "\n",
    "Note that the vector embeddings in a row in C theoretically do not need to match the order of the indices in the row in X;\n",
    "they only need to be consistent with the other rows in C.\n",
    "For this worksheet, though, if the order does differ, the test case will fail.\n",
    "\n",
    "Video: [0:05:55](https://youtu.be/TCH_1BHY58I?t=355), [0:13:07](https://youtu.be/TCH_1BHY58I?t=787) and [0:19:10](https://youtu.be/TCH_1BHY58I?t=1150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5cbf839",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_emb(X, C):\n",
    "    emb = torch.cat(torch.unbind(C[X], 1), 1) # unbind removes a tensor dimension. So index 1 of torch.Size([32, 3, 2]) gives [32, 6]\n",
    "\n",
    "    ## Can be done more efficiently with view\n",
    "    emb = C[X]\n",
    "    return emb.view(len(X), -1) # when you use -1, pytorch will infer the size\n",
    "    return emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a13f380",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_vector_embedding looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_get_vector_embedding():\n",
    "    X = torch.tensor([\n",
    "        [1, 2],\n",
    "        [2, 1],\n",
    "        [0, 1],\n",
    "    ])\n",
    "    ZERO = [0.1, 0.2, 0.3]\n",
    "    ONE = [0.4, 0.5, 0.6]\n",
    "    TWO = [0.7, 0.8, 0.9]\n",
    "    C = torch.tensor([\n",
    "        ZERO,\n",
    "        ONE,\n",
    "        TWO,\n",
    "    ])\n",
    "\n",
    "    emb = get_emb(X, C)\n",
    "\n",
    "    expected_emb = torch.tensor([\n",
    "        ONE + TWO,\n",
    "        TWO + ONE,\n",
    "        ZERO + ONE,\n",
    "    ])\n",
    "    expect_tensor_close(\"emb\", emb, expected_emb)\n",
    "    print(\"get_vector_embedding looks good. Onwards!\")\n",
    "test_get_vector_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6ba11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 6: Initialize weight and bias coefficients\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* the number of inputs (```input_ct```) to each neuron in the current layer\n",
    "  * For the hidden layer, this is equal to the number of cells in each row of emb\n",
    "  * For the output layer, this is equal to the number of neurons in the previous (hidden) layer\n",
    "* the number of neurons (```neuron_ct```) to include in the current layer\n",
    "  * Karpathy chooses to have 100 neurons for the hidden layer\n",
    "  * The output layer should have one neuron for each possible result\n",
    "* A ```torch.Generator``` (```gen```) to provide (pseudo)random initial values for the parameters\n",
    "\n",
    "And returns:\n",
    "* a two-dimensional ```torch.Tensor``` ```W``` of shape (```input_ct```, ```neuron_ct```) of type ```torch.float64```\n",
    "  * each element of ```W``` should be randomly generated\n",
    "* a one-dimensional pytorch.Tensor ```b``` of length ```neuron_ct```\n",
    "  * the elements of ```b``` can be zero\n",
    "\n",
    "Video: [0:18:37](https://youtu.be/TCH_1BHY58I?t=1117), [0:29:17](https://youtu.be/TCH_1BHY58I?t=1757), and [0:38:49](https://youtu.be/TCH_1BHY58I?t=2329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b50f91",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def initialize_W_b(input_ct, neuron_ct, gen):\n",
    "    W = torch.rand((input_ct, neuron_ct), generator=gen, dtype=torch.float64, requires_grad=True)\n",
    "    b = torch.zeros(neuron_ct, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ab82fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W and b look good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_initialize_W_b():\n",
    "    input_ct = 3\n",
    "    neuron_ct = 5\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(12345)\n",
    "    W, b = initialize_W_b(input_ct, neuron_ct, gen)\n",
    "    expect_type(\"W\", W, torch.Tensor)\n",
    "    expect_type(\"b\", b, torch.Tensor)\n",
    "    expect_eq(\"W.dtype\", W.dtype, torch.float64)\n",
    "    expect_eq(\"b.dtype\", b.dtype, torch.float64)\n",
    "    expect_eq(\"W.shape\", W.shape, (input_ct, neuron_ct))\n",
    "    # The comma is required to make expected_b_shape into a single-element tuple\n",
    "    expect_eq(\"b.shape\", b.shape, (neuron_ct,))\n",
    "    print(\"W and b look good. Onwards!\")\n",
    "test_initialize_W_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051842fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 7: Initialize model\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* An integer (```idx_ct```) representing the number of indices to provide embeddings for\n",
    "* An integer (```block_size```) that specifies how many characters to take into account when predicting the next one\n",
    "* An integer (```embedding_size```) representing the length of each embedding vector\n",
    "* An integer (```hidden_layer_size```) that specifies the number of neurons in the hidden layer\n",
    "* A ```torch.Generator``` (```gen```) to provide (pseudo)random initial values for the parameters\n",
    "\n",
    "And returns:\n",
    "* A Model [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) (defined below) with the following fields:\n",
    "  * A ```torch.tensor``` (```C```) representing the embedding vector for each index\n",
    "    * See Step 4\n",
    "  * A two-dimensional ```torch.Tensor``` (```W1```) representing the weights of the hidden layer\n",
    "    * See Step 6\n",
    "  * A one-dimensional ```torch.Tensor``` (```b1```) representing the biases of the hidden layer\n",
    "    * See Step 6\n",
    "  * A two-dimensional ```torch.Tensor``` (```W2```) representing the weights of the output layer\n",
    "    * See Step 6\n",
    "  * A one-dimensional ```torch.Tensor``` (```b2```) representing the biases of the output layer\n",
    "    * See Step 6\n",
    "\n",
    "Note: Karpathy does not use a namedtuple for these fields.\n",
    "\n",
    "Video: [0:32:27](https://youtu.be/TCH_1BHY58I?t=1947)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1ad84c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Model = namedtuple('Model', ['C', 'W1', 'b1', 'W2', 'b2'])\n",
    "\n",
    "def initialize_model(idx_ct, block_size, embedding_size, hidden_layer_size, gen):\n",
    "    C = get_C(idx_ct, embedding_size, gen)\n",
    "    W1, b1 = initialize_W_b(block_size * embedding_size, hidden_layer_size, gen)\n",
    "    W2, b2 = initialize_W_b(hidden_layer_size, idx_ct, gen)\n",
    "    return Model(C, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "752a1d8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_model looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_initialize_model():\n",
    "    idx_ct = 5\n",
    "    block_size = 4\n",
    "    embedding_size = 3\n",
    "    hidden_layer_size = 7\n",
    "    gen = torch.Generator()\n",
    "\n",
    "    C, W1, b1, W2, b2 = initialize_model(idx_ct, block_size, embedding_size, hidden_layer_size, gen)\n",
    "\n",
    "    expect_eq(\"C.shape\", C.shape, (idx_ct, embedding_size))\n",
    "    expect_eq(\"W1.shape\", W1.shape, (block_size * embedding_size, hidden_layer_size))\n",
    "    expect_eq(\"b1.shape\", b1.shape, (hidden_layer_size,))\n",
    "    expect_eq(\"W2.shape\", W2.shape, (hidden_layer_size, idx_ct))\n",
    "    expect_eq(\"b2.shape\", b2.shape, (idx_ct,))\n",
    "    print(\"initialize_model looks good. Onward!\")\n",
    "test_initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a26cbe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 8: Forward propagate through hidden layer\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* a two-dimensional ```torch.Tensor``` ```emb``` as defined in step 5\n",
    "  * This is the input to the hidden layer\n",
    "* a two-dimensional ```torch.Tensor``` ```W1``` as defined in step 6\n",
    "  * This is the hidden layer's weights\n",
    "* a one-dimensional ```torch.Tensor``` ```b1``` as defined in step 6\n",
    "  * This is the hidden layer's biases\n",
    "\n",
    "And returns:\n",
    "* a one-dimensional ```torch.Tensor``` ```h```\n",
    "  * This is the output of the hidden layer after applying a tanh activation function\n",
    "\n",
    "Video: [0:19:14](https://youtu.be/TCH_1BHY58I?t=1155) and [0:27:57](https://youtu.be/TCH_1BHY58I?t=1677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a012816",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_h(emb, W1, b1):\n",
    "    output = torch.tanh(emb @ W1 + b1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3886bf8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_h looks good. Onwards!\n"
     ]
    }
   ],
   "source": [
    "def test_get_h():\n",
    "    emb = torch.tensor([\n",
    "        [0.1, 0.2],\n",
    "        [-.3, 0.4],\n",
    "        [.05, -.06],\n",
    "    ], dtype=torch.float64)\n",
    "    W1 = torch.tensor([\n",
    "        [0.7, 0.8, -0.9, -0.1],\n",
    "        [0.6, 0.5, 0.4, 0.3],\n",
    "    ], dtype=torch.float64)\n",
    "    b1 = torch.tensor([\n",
    "        .09, -.01, .011, -.012\n",
    "    ], dtype=torch.float64)\n",
    "\n",
    "    h = get_h(emb, W1, b1)\n",
    "\n",
    "    expected_h = torch.tensor([\n",
    "        [ 2.7291e-01,  1.6838e-01,  1.0000e-03,  3.7982e-02],\n",
    "        [ 1.1943e-01, -4.9958e-02,  4.1447e-01,  1.3713e-01],\n",
    "        [ 8.8766e-02,  8.6736e-18, -5.7935e-02, -3.4986e-02],\n",
    "    ], dtype=torch.float64)\n",
    "    expect_tensor_close(\"h for test case\", h, expected_h)\n",
    "    print(\"get_h looks good. Onwards!\")\n",
    "test_get_h()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b5db0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 9: Calculate output layer outputs before activation\n",
    "\n",
    "Write a function that takes the following arguments:\n",
    "* a two-dimensional ```torch.Tensor``` ```W2``` as defined in step 6\n",
    "  * This is the output layer's weights\n",
    "* a one-dimensional ```torch.Tensor``` ```b2``` as defined in step 6\n",
    "  * This is the output layer's biases\n",
    "\n",
    "And returns:\n",
    "* a one-dimensional ```torch.Tensor``` ```logits```\n",
    "  * This is the output of the output layer before applying an activation function\n",
    "\n",
    "Video: [0:29:15](https://youtu.be/TCH_1BHY58I?t=1755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e98a5ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_logits(h, W2, b2):\n",
    "    return h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73cf3ae6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_logits looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_get_logits():\n",
    "    h = torch.tensor([\n",
    "        [1.0, 2.0],\n",
    "        [3.0, 4.0],\n",
    "        [5.0, 6.0]\n",
    "    ])\n",
    "    W2 = torch.tensor([\n",
    "        [10.0, 10.1, 11.0, 19.9],\n",
    "        [100.0, -101.1, 0.0, 98.7],\n",
    "    ])\n",
    "    b2 = torch.tensor([\n",
    "        3.0, 5.0, 11.0, 13.0,\n",
    "    ])\n",
    "\n",
    "    logits = get_logits(h, W2, b2)\n",
    "\n",
    "    expected_logits = torch.tensor([\n",
    "        [ 213.0, -187.1,   22.0,  230.3],\n",
    "        [ 433.0, -369.1,   44.0,  467.5],\n",
    "        [ 653.0, -551.1,   66.0,  704.7],\n",
    "    ])\n",
    "    expect_tensor_close(\"logits\", logits, expected_logits)\n",
    "    print(\"get_logits looks good. Onward!\")\n",
    "test_get_logits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c686f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 10: Forward propagate from vector embeddings\n",
    "\n",
    "Video: [0:32:37](https://youtu.be/TCH_1BHY58I?t=1957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f36de6f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def forward_prop(X, model):\n",
    "    emb = get_emb(X, model.C)\n",
    "    h = get_h(emb, model.W1, model.b1)\n",
    "    logits = get_logits(h, model.W2, model.b2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a2287fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_prop looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_forward_prop():\n",
    "    X = torch.tensor([\n",
    "        [0, 4],\n",
    "        [1, 5],\n",
    "        [2, 6],\n",
    "        [3, 7],\n",
    "    ])\n",
    "    C = torch.tensor([\n",
    "        [1.2],\n",
    "        [-0.5],\n",
    "        [0.0],\n",
    "        [-4.0],\n",
    "        [2.1],\n",
    "        [-0.7],\n",
    "        [0.5247],\n",
    "        [3.1],\n",
    "    ])\n",
    "    W1 = torch.tensor([\n",
    "        [2.3, 0.9, 0.7],\n",
    "        [-3.2, 0.8, 1.3],\n",
    "    ])\n",
    "    b1 = torch.tensor([\n",
    "        0.2, 1.1, -0.1\n",
    "    ])\n",
    "    W2 = torch.tensor([\n",
    "        [ 3.4,  4.5],\n",
    "        [ 0.6,  0.5],\n",
    "        [-1.2,  2.2]\n",
    "    ])\n",
    "    b2 = torch.tensor([\n",
    "        0.3, -0.4,\n",
    "    ])\n",
    "\n",
    "    model = Model(C, W1, b1, W2, b2)\n",
    "    logits = forward_prop(X, model)\n",
    "\n",
    "    expected_logits = torch.tensor([\n",
    "        [-3.6945, -2.1998],\n",
    "        [ 4.3266,  1.5829],\n",
    "        [-2.8482, -2.8482],\n",
    "        [-4.0852, -3.1258],\n",
    "    ])\n",
    "    expect_tensor_close(\"logits\", logits, expected_logits)\n",
    "    print(\"forward_prop looks good. Onward!\")\n",
    "test_forward_prop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b566",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 11: Gradient descent\n",
    "\n",
    "Video: [0:38:23](https://youtu.be/TCH_1BHY58I?t=2303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deabd2b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def descend_gradient(t, learning_rate):\n",
    "    t.data += -learning_rate * t.grad\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7508da18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descend_gradient looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_descend_gradient():\n",
    "    t = torch.tensor([\n",
    "        [1.0, 2.0, 3.0],\n",
    "        [4.0, 5.0, 6.0]\n",
    "    ])\n",
    "    t.grad = torch.tensor([\n",
    "        [0.5, 0.3, 0.1],\n",
    "        [-0.2, -0.4, -0.6]\n",
    "    ])\n",
    "    learning_rate = 2.0\n",
    "\n",
    "    descend_gradient(t, learning_rate)\n",
    "\n",
    "    expected_t = torch.tensor([\n",
    "        [0.0, 1.4, 2.8],\n",
    "        [4.4, 5.8, 7.2]\n",
    "    ])\n",
    "    expect_tensor_close(\"t\", t, expected_t)\n",
    "    print(\"descend_gradient looks good. Onward!\")\n",
    "test_descend_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1589a2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 12: Train model once\n",
    "\n",
    "Video: [0:37:57](https://youtu.be/TCH_1BHY58I?t=2277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a9a7f12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_once(X, Y, model, learning_rate):\n",
    "    # Forward pass\n",
    "    logits = forward_prop(X, model)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "\n",
    "    # model contain parameters Model(C, W1, b1, W2, b2) which we want to reset\n",
    "    for parameter in model:\n",
    "        parameter.grad = None\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update values\n",
    "    for parameter in model:\n",
    "        descend_gradient(parameter, learning_rate)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10157922",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_once looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_train_once():\n",
    "    X = torch.tensor([\n",
    "        [2, 1, 0, 1],\n",
    "        [0, 0, 1, 2],\n",
    "    ])\n",
    "    Y = torch.tensor([\n",
    "        0,\n",
    "        1,\n",
    "    ])\n",
    "    C = torch.tensor([\n",
    "        [1.0],\n",
    "        [-1.0],\n",
    "        [0.5],\n",
    "    ], requires_grad=True)\n",
    "    W1 = torch.tensor([\n",
    "        [1.0],\n",
    "        [1.1],\n",
    "        [2.1],\n",
    "        [-2.9]\n",
    "    ], requires_grad=True)\n",
    "    b1 = torch.tensor([\n",
    "        [0.1],\n",
    "    ], requires_grad=True)\n",
    "    W2 = torch.tensor([\n",
    "        [1.0, 2.0, 3.0]\n",
    "    ], requires_grad=True)\n",
    "    b2 = torch.tensor([\n",
    "        1.0, 0.9, 0.8\n",
    "    ], requires_grad=True)\n",
    "    model = Model(C, W1, b1, W2, b2)\n",
    "    learning_rate = 1.0\n",
    "    loss = train_once(X, Y, model, learning_rate)\n",
    "    expect_close(\"loss\", loss, 1.8224)\n",
    "    print(\"train_once looks good. Onward!\")\n",
    "test_train_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab87d9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 13: Initialize indices and model\n",
    "\n",
    "Video: [0:37:56](https://youtu.be/TCH_1BHY58I?t=2276)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b20b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_words = load_words()\n",
    "stoi = get_stoi(loaded_words)\n",
    "itos = get_itos(stoi)\n",
    "\n",
    "idx_ct = len(stoi)\n",
    "block_size = 4\n",
    "embedding_size = 3\n",
    "hidden_layer_size = 50\n",
    "gen = torch.Generator()\n",
    "model = initialize_model(idx_ct, block_size, embedding_size, hidden_layer_size, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2229125",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 14: Initialize examples and labels\n",
    "\n",
    "Video: [0:53:20](https://youtu.be/TCH_1BHY58I?t=3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47d8b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(loaded_words)\n",
    "train = int(0.5 * len(loaded_words))\n",
    "dev = int(0.8 * len(loaded_words))\n",
    "Xtr, Ytr = get_X_and_Y(loaded_words[0:train], stoi, block_size)\n",
    "Xdev, Ydev = get_X_and_Y(loaded_words[train:dev], stoi, block_size)\n",
    "Xtest, Ytest = get_X_and_Y(loaded_words[dev:], stoi, block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f9ad8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 15: Train the model repeatedly in minibatches\n",
    "\n",
    "Video: [0:38:38](https://youtu.be/TCH_1BHY58I?t=2318) and [0:42:22](https://youtu.be/TCH_1BHY58I?t=2542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b0b5ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3.6923130435931575\n",
      "2000: 2.3577522772400203\n",
      "4000: 2.0985890937307055\n",
      "6000: 2.5751385961626156\n",
      "8000: 1.9315196653399789\n",
      "10000: 2.050191850843082\n",
      "12000: 2.3767146861912867\n",
      "14000: 2.516794670353144\n",
      "16000: 2.305662078198077\n",
      "18000: 1.9753183244398447\n",
      "20000: 2.1642676815663853\n",
      "22000: 1.8870844411254368\n",
      "24000: 2.3308721983758245\n",
      "26000: 2.0392922353634084\n",
      "28000: 2.021849100846925\n",
      "Dev loss is 2.262103736242258\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .5\n",
    "minibatch_size = 32\n",
    "\n",
    "for i in range(1, 30000, 1):\n",
    "    ix = torch.randint(0, Xtr.shape[0], (minibatch_size,), generator=gen)\n",
    "    X_mini = Xtr[ix]\n",
    "    Y_mini = Ytr[ix]\n",
    "    loss = train_once(X_mini, Y_mini, model, learning_rate)\n",
    "    if i == 1 or i % 2000 == 0:\n",
    "        print(f\"{i}: {loss}\")\n",
    "\n",
    "logits = forward_prop(Xdev, model)\n",
    "loss = torch.nn.functional.cross_entropy(logits, Ydev)\n",
    "print(f\"Dev loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ca881",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 16: Measure the model's testing loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82403c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss is 2.262873320590516\n"
     ]
    }
   ],
   "source": [
    "logits = forward_prop(Xtest, model)\n",
    "loss = torch.nn.functional.cross_entropy(logits, Ytest)\n",
    "print(f\"Testing loss is {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6dd7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 17: Get inputs to find probabilities for\n",
    "\n",
    "Video: [1:13:31](https://youtu.be/TCH_1BHY58I?t=4411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "161e16f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_sampling_inputs(block_size, stoi, word):\n",
    "    padded_word = block_size * '.' + word  # Add start-of-word characters in case len(word) < block_size\n",
    "    block_letters = padded_word[-block_size:]\n",
    "    block_idxes = [stoi[c] for c in block_letters]\n",
    "    inputs = torch.tensor([block_idxes])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3b60780",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_sampling_inputs looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_get_sampling_inputs():\n",
    "    block_size = 4\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'h': 1,\n",
    "        'i': 2,\n",
    "    }\n",
    "    word = \"hi\"\n",
    "\n",
    "    inputs = get_sampling_inputs(block_size, stoi, word)\n",
    "\n",
    "    expect_tensor_close(\"inputs\", inputs, torch.tensor([[0, 0, 1, 2]]))\n",
    "    print(\"get_sampling_inputs looks good. Onward!\")\n",
    "test_get_sampling_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16fb74",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 18: Sample probability distribution\n",
    "\n",
    "Video: [1:14:18](https://youtu.be/TCH_1BHY58I?t=4458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28a9f8d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def sample_distribution(probability_distribution, gen):\n",
    "    num_samples = 1  # we only need one letter\n",
    "    sample_idx = torch.multinomial(probability_distribution, num_samples, generator=gen).item()\n",
    "    return sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8768a566",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_distribution looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_sample_distribution():\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(12345)\n",
    "    probability_distribution = torch.tensor([0.6, 0.1, 0.3])\n",
    "    count = 10000\n",
    "\n",
    "    samples = torch.zeros(3)\n",
    "    for _ in range(count):\n",
    "        samples[sample_distribution(probability_distribution, gen)] += 1\n",
    "\n",
    "    expected_samples = probability_distribution * count\n",
    "    expect_tensor_close(\"samples\", samples, expected_samples, atol = 200)\n",
    "    print(\"sample_distribution looks good. Onward!\")\n",
    "test_sample_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631defa0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 19: Generate a word by sampling\n",
    "\n",
    "Video: [1:13:24](https://youtu.be/TCH_1BHY58I?t=4404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11fdeca8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_word(model, block_size, stoi, itos, sample_distribution_func, gen):\n",
    "    word = \"\"\n",
    "    while True:\n",
    "        inputs = get_sampling_inputs(block_size, stoi, word)\n",
    "        logits = forward_prop(inputs, model)\n",
    "        probability_distribution = torch.nn.functional.softmax(logits, 1)\n",
    "        sample_idx = sample_distribution_func(probability_distribution, gen)\n",
    "        sample = itos[sample_idx]\n",
    "        if sample == '.':\n",
    "            break\n",
    "        word += sample\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eef365c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_word looks good. Onward!\n"
     ]
    }
   ],
   "source": [
    "def test_generate_word():\n",
    "    stoi = {\n",
    "        '.': 0,\n",
    "        'a': 1,\n",
    "        'd': 2,\n",
    "        'n': 3,\n",
    "        'o': 4,\n",
    "        'r': 5,\n",
    "        'w': 6\n",
    "    }\n",
    "    itos = {v:k for k,v in stoi.items()}\n",
    "    block_size = 3\n",
    "    C = torch.tensor([\n",
    "        [ 1.0,  0.1],\n",
    "        [-0.9,  0.3],\n",
    "        [ 0.2,  0.5],\n",
    "        [-0.3,  0.6],\n",
    "        [ 0.6, -0.4],\n",
    "        [-0.7, -0.8],\n",
    "        [-0.1,  0.9],\n",
    "    ])\n",
    "    W1 = torch.tensor([\n",
    "        [ 1.3,  0.9],\n",
    "        [ 0.7, -0.3],\n",
    "        [-0.5,  1.4],\n",
    "        [-3.2,  0.8],\n",
    "        [ 1.3, -0.6],\n",
    "        [ 1.4, -0.2],\n",
    "    ])\n",
    "    b1 = torch.tensor([\n",
    "        0.2, 1.1\n",
    "    ])\n",
    "    W2 = torch.tensor([\n",
    "        [ 3.4,  4.5, -1.8,  0.7,  0.4,  0.1, -1.1],\n",
    "        [ 0.6,  0.5,  2.1, -0.9,  1.1, -0.3,  0.8],\n",
    "    ])\n",
    "    b2 = torch.tensor([\n",
    "        0.3, -0.4, 0.2, -0.8, 0.0, -0.1, 1.1\n",
    "    ])\n",
    "\n",
    "    model = Model(C, W1, b1, W2, b2)\n",
    "\n",
    "    target_pos = 0\n",
    "    target_seq = [0.98, 0.895, 0.99, 0.18, 0.74, 0.25, 0.0]\n",
    "    def mock_sample(probability_distribution, _):\n",
    "        nonlocal target_pos\n",
    "        target_sum = target_seq[target_pos]\n",
    "        prob_sum = 0.0\n",
    "        dist_pos = 0\n",
    "        while True:\n",
    "            prob_sum += probability_distribution[0][dist_pos]\n",
    "            if prob_sum >= target_sum:\n",
    "                break\n",
    "            dist_pos += 1\n",
    "        target_pos += 1\n",
    "        return dist_pos\n",
    "\n",
    "    word = generate_word(model, block_size, stoi, itos, mock_sample, None)\n",
    "\n",
    "    expect_eq(\"word\", word, \"onward\")\n",
    "    print(\"generate_word looks good. Onward!\")\n",
    "test_generate_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61c2fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 20: Generate words\n",
    "\n",
    "Video: [1:13:24](https://youtu.be/TCH_1BHY58I?t=4404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fcfa8f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nn\n",
      "luwr\n",
      "d\n",
      "fren\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(generate_word(model, block_size, stoi, itos, sample_distribution, gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b9ca1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Bonus: Calculate probability of an empty word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42f0119e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_empty_word_prob(model, stoi):\n",
    "    logits = forward_prop(torch.tensor([[0,0,0]]), model)\n",
    "    print(logits)\n",
    "    probs = torch.nn.functional.softmax(logits, 1)[0]\n",
    "    prob_empty = probs[stoi['.']]\n",
    "\n",
    "    return prob_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d2220db",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x9 and 12x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob_empty \u001b[38;5;241m=\u001b[39m \u001b[43mget_empty_word_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstoi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe probability of this model generating an empty word is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprob_empty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[78], line 2\u001b[0m, in \u001b[0;36mget_empty_word_prob\u001b[0;34m(model, stoi)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_empty_word_prob\u001b[39m(model, stoi):\n\u001b[0;32m----> 2\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mforward_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[1;32m      4\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m, in \u001b[0;36mforward_prop\u001b[0;34m(X, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_prop\u001b[39m(X, model):\n\u001b[1;32m      2\u001b[0m     emb \u001b[38;5;241m=\u001b[39m get_emb(X, model\u001b[38;5;241m.\u001b[39mC)\n\u001b[0;32m----> 3\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mget_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     logits \u001b[38;5;241m=\u001b[39m get_logits(h, model\u001b[38;5;241m.\u001b[39mW2, model\u001b[38;5;241m.\u001b[39mb2)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mget_h\u001b[0;34m(emb, W1, b1)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_h\u001b[39m(emb, W1, b1):\n\u001b[0;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x9 and 12x50)"
     ]
    }
   ],
   "source": [
    "prob_empty = get_empty_word_prob(model, stoi)\n",
    "print(f\"The probability of this model generating an empty word is {prob_empty}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07cced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
